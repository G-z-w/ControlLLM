tool_assessment_prompt = """Given a task and a tool, the AI assistant helps the system to decide whether this tool can process the task. The assistant should focus more on the description of the model and give a score to each tool.

The AI assistant respond with JSON format as follows: <Solution>{"Thought": "thought", "Score": score}</Solution>.

"Thought" filed records the model’s thinking process step by step within 80 words, which give the reasons why assistant gives this score.

"Score" filed denotes score that uses to assess whether this tool is useful for this task. Score is in [1, 2, 3, 4, 5]. Here is the scoring criteria: "Score"=1: the tool is totally not related to the task and does not provide any useful output for solving the task. "Score"=2: the tool is somewhat not related to the task and may not provide any useful output for solving the task. "Score"=3: the tool is probably related to the task and provides some intermediate output that is partially helpful for solving the task but it may not be the optimal one. "Score">3: the tool is closely or directly related to the task and provides output that is mostly helpful for solving the task, or that matches the returns of the task with regard to the type. In a nut shell, for the given task, the higher the score, the more useful the tool is.

You should always respond in the following format:

<Solution> `SOLUTION` </Solution>

`SOLUTION` should strictly comply with JSON format described above."""
"""Given a task and a tool, the AI assistant helps the system to decide whether this tool can process the task. The assistant should focus more on the description of the model and give a score to each tool.

The AI assistant respond with JSON format as follows: <Solution>{"Thought": "thought", "Score": score}</Solution>.

"Thought" filed records the model’s thinking process step by step within 80 words, which give the reasons why assistant gives this score.

"Score" filed denotes score that uses to assess whether this tool is useful for this task. Score is in [1, 2, 3, 4, 5]. Here is the scoring criteria: "Score"<3: The tool is somewhat or not related to the task and does not provide any useful output for solving the task. "Score"=3: The tool is related to the task and provides some intermediate output that is partially helpful for solving the task. "Score">3: The tool is closely or directly related to the task and provides output that is mostly helpful for solving the task, or that matches the returns of the task with regard to the type. In a nut shell, for the given task, the higher the score, the more useful the tool is.

You should always respond in the following format:

<Solution> `SOLUTION` </Solution>

`SOLUTION` should strictly comply with JSON format described above."""

prompts = dict(
    memory=dict(max_tokens=-1),
    tool_assessment_prompt=tool_assessment_prompt,
    solution_selection_examples=[
        {
            "role": "user",
            "content": """User's request: [ what is it in sdf.png ].
        Here is the Task: [{"task_description": "detect the object in sdf.png", "task": "image-perception", "id": 0, "dep": [-1], "args": {"sdf.png": "image", "what is it in sdf.png": "text"}, "returns": {"<GENERATED>-0": "text"}}].
        User's request and task description may contain the information that is useful for AI to make decision.
        Here is the solution proposals to solve the task: [ {{solutions}} ]""",
        },
        {
            "role": "assistant",
            "content": "<Solution>[{\"task_description\": \"Generate an image of a mountain and animals.\", \"task\": [\"image-generation\"], \"id\": 0, \"dep\": [-1], \"args\": {\"Generate an image of a mountain and animals\": \"text\"}, \"returns\": {\"<GENERATED>-0\": \"image\"}}, {\"task_description\": \"Perform visual question-answering on the generated image to count the number of animals.\", \"task\": \"image-perception\", \"id\": 1, \"dep\": [0], \"args\": {\"<GENERATED>-0\": \"image\"}, \"returns\": {\"<GENERATED>-1\": \"text\"}}]</Solution>",
        },
    ],
    resource_search_examples=[
        {
            "role": "system",
            "content": """Here is the chat log [ <assistant>: The required input for detr is already provided in the <Resources> as "sdf.png". Therefore, the inputs for detr are: <Solution>[{"image": "sdf.png"}]</Solution>
        ], which contains the previous steps to solve this task.

        <Resources>: ["sdf.png": it is image and provided by user input.
        "detect the dog in sdf.png": it is text and provided by user input.
        "<GENERATED>-detr-bbox-0": it is bbox and generated by tool "detr".
        ]

        We use CropImageByBBox to solve this task: 
        CropImageByBBox: Crop the image by bounding box (bbox). Useful when you want to extract or save the masked region in the image.
        Inputs: ['image', 'bbox']
        Returns: ["image"]

        Now we prepare the inputs for CropImageByBBox: [{"image": "______"}, {"bbox": "<GENERATED>-detr-bbox-0"}] Please select the resource in <Resources> to complete this inputs.""",
        },
        {
            "role": "assistant",
            "content": """<Solution>[{"image": "sdf.png"}, {"bbox": "<GENERATED>-detr-bbox-0"}]</Solution>""",
        },
    ],
)
